city_name,
"/schools/?page=",
sep = "")
#school_list_url_left <- "https://www.greatschools.org/california/santa-barbara/schools/?page="
school_list_url_right <- "&view=table"
school_list_js_xpath <- "/html/head/script[1]"
### Scrape list page
source("scripts/scrape_school_lists.R")
### Create school review URLs
school_url_left <- 'https://www.greatschools.org'
v_school_url_right <- gsub("#Reviews", "reviews/", df_schools$reviews)
v_school_urls <- paste0(school_url_left, v_school_url_right)
v_school_urls <- setdiff(v_school_urls[df_schools$num_reviews > 0], NA)
### RSelenium
rD <- rsDriver(browser = "firefox")
remDr <- rD[["client"]]
Sys.sleep(5)
remDr$setWindowSize(width = 1920 / 2, height = 1080) # Ensures window is the right size for scrolling
### Scrape review pages
for (s in 1:length(v_school_urls)) {
school_url <- v_school_urls[s]
print(paste("Scraping: ", school_url))
source("scrape_school_reviews.R")
if (s == 1) {
df_all_school_reviews <- df_school_review
} else{
df_all_school_reviews <- bind_rows(df_all_school_reviews,
df_school_review)
}
Sys.sleep(5)
}
remDr$close()
rD$server$stop()
rm(rD)
#system("taskkill /im java.exe /f", intern=FALSE, ignore.stdout=FALSE)
data_path <- "../data/"
school_list_outfile <- paste0(city_name, "_list.RData", sep = "")
save(df_schools, file = paste(data_path, school_list_outfile, sep = ""))
school_reviews_outfile <- paste(city_name, "_reviews.RData", sep = "")
save(df_all_school_reviews, file = paste(data_path, school_reviews_outfile, sep = ""))
data_path <- "data/"
school_list_outfile <- paste0(city_name, "_list.RData", sep = "")
save(df_schools, file = paste(data_path, school_list_outfile, sep = ""))
school_reviews_outfile <- paste(city_name, "_reviews.RData", sep = "")
save(df_all_school_reviews, file = paste(data_path, school_reviews_outfile, sep = ""))
### Libraries
library(tidyverse)
library(rvest)
library(RSelenium)
library(V8)
library(jsonlite)
library(stringr)
library(snakecase)
### Inputs
state_name <- "california"
#city_name <- "santa barbara" # 5 pages
city_name <- "goleta" # 2 pages
#city_name <- "summerland" # 1 page
#city_name <- "montecito" # 1 page
#city_name <- "carpinteria" # 1 page
#city_name <- "ojai" # 2 pages
#city_name <- "ventura" # 4 page
#city_name <- "santa-ynez" # 1 page
#city_name <- "solvang" # 1 pages
#city_name <- "buellton" # 1 pages
### Create URLs
city_name <- gsub(" ", "-", city_name)
school_list_url_left <- paste0("https://www.greatschools.org/",
state_name,
"/",
city_name,
"/schools/?page=",
sep = "")
#school_list_url_left <- "https://www.greatschools.org/california/santa-barbara/schools/?page="
school_list_url_right <- "&view=table"
school_list_js_xpath <- "/html/head/script[1]"
### Scrape list page
source("scripts/scrape_school_lists.R")
### Create school review URLs
school_url_left <- 'https://www.greatschools.org'
v_school_url_right <- gsub("#Reviews", "reviews/", df_schools$reviews)
v_school_urls <- paste0(school_url_left, v_school_url_right)
v_school_urls <- setdiff(v_school_urls[df_schools$num_reviews > 0], NA)
### RSelenium
rD <- rsDriver(browser = "firefox")
remDr <- rD[["client"]]
Sys.sleep(5)
remDr$setWindowSize(width = 1920 / 2, height = 1080) # Ensures window is the right size for scrolling
### Scrape review pages
for (s in 1:length(v_school_urls)) {
school_url <- v_school_urls[s]
print(paste("Scraping: ", school_url))
source("scrape_school_reviews.R")
if (s == 1) {
df_all_school_reviews <- df_school_review
} else{
df_all_school_reviews <- bind_rows(df_all_school_reviews,
df_school_review)
}
Sys.sleep(5)
}
remDr$close()
rD$server$stop()
rm(rD)
#system("taskkill /im java.exe /f", intern=FALSE, ignore.stdout=FALSE)
data_path <- "data/"
school_list_outfile <- paste0(city_name, "_list.RData", sep = "")
save(df_schools, file = paste(data_path, school_list_outfile, sep = ""))
school_reviews_outfile <- paste(city_name, "_reviews.RData", sep = "")
save(df_all_school_reviews, file = paste(data_path, school_reviews_outfile, sep = ""))
source("scripts/scrape_school_reviews.R")
### Libraries
library(tidyverse)
library(rvest)
library(RSelenium)
library(V8)
library(jsonlite)
library(stringr)
library(snakecase)
### Inputs
state_name <- "california"
#city_name <- "santa barbara" # 5 pages
city_name <- "goleta" # 2 pages
#city_name <- "summerland" # 1 page
#city_name <- "montecito" # 1 page
#city_name <- "carpinteria" # 1 page
#city_name <- "ojai" # 2 pages
#city_name <- "ventura" # 4 page
#city_name <- "santa-ynez" # 1 page
#city_name <- "solvang" # 1 pages
#city_name <- "buellton" # 1 pages
### Create URLs
city_name <- gsub(" ", "-", city_name)
school_list_url_left <- paste0("https://www.greatschools.org/",
state_name,
"/",
city_name,
"/schools/?page=",
sep = "")
#school_list_url_left <- "https://www.greatschools.org/california/santa-barbara/schools/?page="
school_list_url_right <- "&view=table"
school_list_js_xpath <- "/html/head/script[1]"
### Scrape list page
source("scripts/scrape_school_lists.R")
### Create school review URLs
school_url_left <- 'https://www.greatschools.org'
v_school_url_right <- gsub("#Reviews", "reviews/", df_schools$reviews)
v_school_urls <- paste0(school_url_left, v_school_url_right)
v_school_urls <- setdiff(v_school_urls[df_schools$num_reviews > 0], NA)
### RSelenium
rD <- rsDriver(browser = "firefox")
remDr <- rD[["client"]]
Sys.sleep(5)
remDr$setWindowSize(width = 1920 / 2, height = 1080) # Ensures window is the right size for scrolling
### Scrape review pages
for (s in 1:length(v_school_urls)) {
school_url <- v_school_urls[s]
print(paste("Scraping: ", school_url))
source("scripts/scrape_school_reviews.R")
if (s == 1) {
df_all_school_reviews <- df_school_review
} else{
df_all_school_reviews <- bind_rows(df_all_school_reviews,
df_school_review)
}
Sys.sleep(5)
}
remDr$close()
rD$server$stop()
rm(rD)
system("taskkill /im java.exe /f", intern=FALSE, ignore.stdout=FALSE)
data_path <- "data/"
school_list_outfile <- paste0(city_name, "_list.RData", sep = "")
save(df_schools, file = paste(data_path, school_list_outfile, sep = ""))
school_reviews_outfile <- paste(city_name, "_reviews.RData", sep = "")
save(df_all_school_reviews, file = paste(data_path, school_reviews_outfile, sep = ""))
rD <- rsDriver(browser = "firefox")
pid <- driver$server$process$get_pid()
pid <- rD$server$process$get_pid()
pid
remDr <- rD[["client"]]
remDr$close()
rD$server$stop()
rm(rD)
gc(rD)
system(paste0("Taskkill /F /T" ," /PID ", pid))
session <- bow(school_list_url_left)
library(polite)
session <- bow(school_list_url_left)
session
library(tidyverse)
library(rvest)
library(V8)
library(jsonlite)
library(snakecase)
library(polite)
## URLS
#school_list_url_left <- "https://www.greatschools.org/california/santa-barbara/schools/?page="
#school_list_url_right <- "&view=table"
#school_list_js_xpath <- "/html/head/script[1]"
session <- bow(school_list_url_left)
# Nod and scrape page politely
current_page <- nod(session, t_url) %>%
scrape(verbose = FALSE)
## List scraping function
fn_scrape_school_page <- function(my_left_url, my_page_num, my_right_url){
url <- paste(my_left_url, my_page_num, my_right_url, sep = "")
current_page <- nod(session, url) %>% scrape(verbose = FALSE)
current_page %>%
#  read_html(url) %>%
html_element(xpath = school_list_js_xpath) %>%
html_text(trim = TRUE) %>%
str_replace(fixed("window.gon"), "gon") -> txt
tmp <- tempfile()
write_file(
txt,
file = tmp
)
txt2 <- read_lines(
tmp
)
ctx <- v8()
ctx$eval(txt2[2])
l_school_reviews <- ctx$get("gon")
total_pages <- l_school_reviews$search$totalPages
my_df <- data.frame(l_school_reviews$search$schools,
pg_num = my_page_num,
tot_pages = total_pages)
df_ethnicity_info <- data.frame()
for (i in 1:length(my_df$id)){
my_df$ethnicityInfo[[i]] %>%
pivot_wider(names_from = label,
values_from = setdiff(names(my_df$ethnicityInfo[[i]]), "label"),
names_glue = "{.value}_{label}",
names_sep = "_") %>%
mutate(id = my_df$id[i]) %>%
bind_rows(df_ethnicity_info) -> df_ethnicity_info
}
my_df <- left_join(my_df, df_ethnicity_info, by = c("id"))
return(my_df)
}
## Scrape school list
df_schools <- data.frame()
page_to_scrape <- 1
total_pages <- 2
while (page_to_scrape <= total_pages){
print(paste("Scraping page", page_to_scrape))
df_schools <- bind_rows(df_schools,
fn_scrape_school_page(school_list_url_left,
page_to_scrape,
school_list_url_right))
page_to_scrape <- page_to_scrape + 1
total_pages <- max(df_schools$tot_pages)
Sys.sleep(5)
}
# Scraping review pages
## Libraries
library(RSelenium)
library(rvest)
library(stringr)
## Setting up page to scrape
### URL
#school_url <- "https://www.greatschools.org/california/santa-barbara/11279-Crane-Country-Day-School/reviews/"
### Navigate to page
remDr$navigate(school_url)
### Scroll down to show all reviews
### expand reviews by clicking on "more" links
while (length(remDr$findElements("link text", "More")) != 0) {
print(paste("Found", length(remDr$findElements("link text", "More")), "link(s) to click. Clicking and scrolling!"))
remDr$findElements("link text", "More")[[1]]$clickElement()
remDr$executeScript(paste("scroll(0,", i * 1080, ");"))
Sys.sleep(1)
}
## Read page source
#webpage <- read_html(remDr$getPageSource()[[1]])
webpage <- nod(session, remDr$getPageSource()[[1]])
## Start extracting elements
### Extract global elements
webpage %>%
html_elements(".community-breadcrumbs a") %>%
html_text() -> school_name
webpage %>%
html_elements("div.review-item-container") -> review_container
review_container %>%
html_element("div.user-type") %>%
html_text() -> user_type
review_container %>%
html_element("div.comment") %>%
html_text() -> overall_comments
review_container %>%
html_element("div.answer") %>%
as.character() %>%
str_count("filled-star") -> overall_rating
review_container %>%
html_element("span.type-and-date") %>%
html_text() %>%
as.Date("%B %d, %Y") -> review_date
### Extract topic reviews
review_container %>%
html_elements("div.topic") %>%
length() -> num_topic_reviews
review_container %>%
html_elements("div.topic") %>%
html_text() -> topic_labels
review_container %>%
html_elements("div.topical-review-detail") %>%
html_element("div.comment") %>%
html_text() -> topic_comments
#### Function to extract topic comments
review_index <- rep(1:length(num_topic_reviews), times = num_topic_reviews)
fn_extract_topic_comments <- function(my_topic) {
tmp <- rep(NA, times = length(review_date))
tmp[review_index[topic_labels == my_topic]] <- topic_comments[which(topic_labels == my_topic)]
return(tmp)
}
#### Extract topic comments
homework_comments <- fn_extract_topic_comments("Homework")
teacher_comments <- fn_extract_topic_comments("Teachers")
character_comments <- fn_extract_topic_comments("Character")
leadership_comments <- fn_extract_topic_comments("Leadership")
bullying_comments <- fn_extract_topic_comments("Bullying")
learning_diffs_comments <- fn_extract_topic_comments("Learning Differences")
### Topic ratings
review_container %>%
html_elements("div.topical-item") %>%
html_element("div.topic-details") %>%
html_text() -> topic_rating_label
review_container %>%
html_elements("div.topical-item") %>%
html_element("div.topical-average") %>%
html_element("div.numeric") %>%
html_text() %>%
as.numeric() -> topic_rating
review_container %>%
str_count('<div class="topical-item"') -> num_topic_ratings
webpage %>%
as.character() %>%
str_count('<div class="topical-item"') -> num_topic_ratings
#### Function to extract topic ratings
review_index_ratings <- rep(1:length(num_topic_reviews), times = num_topic_ratings)
fn_extract_topic_rating <- function(my_topic) {
tmp <- rep(NA, times = length(review_date))
tmp[review_index_ratings[grep(my_topic, topic_rating_label)]] <-
topic_rating[grep(my_topic, topic_rating_label)]
return(tmp)
}
#### Extract topic ratings
homework_rating <- fn_extract_topic_rating("Homework")
teacher_rating <- fn_extract_topic_rating("Teachers")
character_rating <- fn_extract_topic_rating("Character")
leadership_rating <- fn_extract_topic_rating("Leadership")
bullying_rating <- fn_extract_topic_rating("Bullying")
learning_diffs_rating <- fn_extract_topic_rating("Learning Differences")
## Combine everything together in data frame
df_school_review <- data.frame(
school_name,
user_type,
review_date,
overall_rating,
overall_comments,
homework_rating,
teacher_rating,
character_rating,
leadership_rating,
bullying_rating,
learning_diffs_rating,
homework_comments,
teacher_comments,
character_comments,
leadership_comments,
bullying_comments,
learning_diffs_comments
)
### Libraries
library(tidyverse)
library(rvest)
library(RSelenium)
library(V8)
library(jsonlite)
library(stringr)
library(snakecase)
library(polite)
### Inputs
state_name <- "california"
#city_name <- "santa barbara" # 5 pages
city_name <- "goleta" # 2 pages
#city_name <- "summerland" # 1 page
#city_name <- "montecito" # 1 page
#city_name <- "carpinteria" # 1 page
#city_name <- "ojai" # 2 pages
#city_name <- "ventura" # 4 page
#city_name <- "santa-ynez" # 1 page
#city_name <- "solvang" # 1 pages
#city_name <- "buellton" # 1 pages
### Create URLs
city_name <- gsub(" ", "-", city_name)
school_list_url_left <- paste0("https://www.greatschools.org/",
state_name,
"/",
city_name,
"/schools/?page=",
sep = "")
#school_list_url_left <- "https://www.greatschools.org/california/santa-barbara/schools/?page="
school_list_url_right <- "&view=table"
school_list_js_xpath <- "/html/head/script[1]"
### Scrape list page
source("scripts/scrape_school_lists.R")
### Create school review URLs
school_url_left <- 'https://www.greatschools.org'
v_school_url_right <- gsub("#Reviews", "reviews/", df_schools$reviews)
v_school_urls <- paste0(school_url_left, v_school_url_right)
v_school_urls <- setdiff(v_school_urls[df_schools$num_reviews > 0], NA)
### RSelenium
rD <- rsDriver(browser = "firefox")
remDr <- rD[["client"]]
Sys.sleep(5)
remDr$setWindowSize(width = 1920 / 2, height = 1080) # Ensures window is the right size for scrolling
### Scrape review pages
for (s in 1:length(v_school_urls)) {
school_url <- v_school_urls[s]
print(paste("Scraping: ", school_url))
source("scripts/scrape_school_reviews.R")
if (s == 1) {
df_all_school_reviews <- df_school_review
} else{
df_all_school_reviews <- bind_rows(df_all_school_reviews,
df_school_review)
}
Sys.sleep(5)
}
#pid <- rD$server$process$get_pid()
#system(paste0("Taskkill /F /T" ," /PID ", pid))
remDr$close()
rD$server$stop()
rm(rD)
data_path <- "data/"
school_list_outfile <- paste0(city_name, "_list.RData", sep = "")
save(df_schools, file = paste(data_path, school_list_outfile, sep = ""))
school_reviews_outfile <- paste(city_name, "_reviews.RData", sep = "")
save(df_all_school_reviews, file = paste(data_path, school_reviews_outfile, sep = ""))
remDr$close()
rD$server$stop()
rm(rD)
### Libraries
library(tidyverse)
library(rvest)
library(RSelenium)
library(V8)
library(jsonlite)
library(stringr)
library(snakecase)
library(polite)
### Inputs
state_name <- "california"
#city_name <- "santa barbara" # 5 pages
city_name <- "goleta" # 2 pages
#city_name <- "summerland" # 1 page
#city_name <- "montecito" # 1 page
#city_name <- "carpinteria" # 1 page
#city_name <- "ojai" # 2 pages
#city_name <- "ventura" # 4 page
#city_name <- "santa-ynez" # 1 page
#city_name <- "solvang" # 1 pages
#city_name <- "buellton" # 1 pages
### Create URLs
city_name <- gsub(" ", "-", city_name)
school_list_url_left <- paste0("https://www.greatschools.org/",
state_name,
"/",
city_name,
"/schools/?page=",
sep = "")
#school_list_url_left <- "https://www.greatschools.org/california/santa-barbara/schools/?page="
school_list_url_right <- "&view=table"
school_list_js_xpath <- "/html/head/script[1]"
### Scrape list page
source("scripts/scrape_school_lists.R")
### Create school review URLs
school_url_left <- 'https://www.greatschools.org'
v_school_url_right <- gsub("#Reviews", "reviews/", df_schools$reviews)
v_school_urls <- paste0(school_url_left, v_school_url_right)
v_school_urls <- setdiff(v_school_urls[df_schools$num_reviews > 0], NA)
### RSelenium
rD <- rsDriver(browser = "firefox")
remDr <- rD[["client"]]
Sys.sleep(5)
remDr$setWindowSize(width = 1920 / 2, height = 1080) # Ensures window is the right size for scrolling
### Scrape review pages
for (s in 1:length(v_school_urls)) {
school_url <- v_school_urls[s]
print(paste("Scraping: ", school_url))
source("scripts/scrape_school_reviews.R")
if (s == 1) {
df_all_school_reviews <- df_school_review
} else{
df_all_school_reviews <- bind_rows(df_all_school_reviews,
df_school_review)
}
Sys.sleep(5)
}
#pid <- rD$server$process$get_pid()
#system(paste0("Taskkill /F /T" ," /PID ", pid))
remDr$close()
rD$server$stop()
rm(rD)
data_path <- "data/"
school_list_outfile <- paste0(city_name, "_list.RData", sep = "")
save(df_schools, file = paste(data_path, school_list_outfile, sep = ""))
school_reviews_outfile <- paste(city_name, "_reviews.RData", sep = "")
save(df_all_school_reviews, file = paste(data_path, school_reviews_outfile, sep = ""))
pid <- rD$server$process$get_pid()
system(paste0("Taskkill /F /T" ," /PID ", pid))
